{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ps2022-lab1",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinagoros/vinagoros/blob/main/lab1/ps2022_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgFZlT_g8O1Y"
      },
      "source": [
        "# Processamento de Streams 2022\n",
        "## Lab 1\n",
        "---\n",
        "### Colab Setup Basics\n",
        "\n",
        "This notebook shows how to run Spark in Google Colab.\n",
        "\n",
        "The main drawback is the Google Colab execution environment is not persistent. The notebook itself is saved in Google Drive, but Spark and any other software installation needs to be repeated everytime you reopen the notebook. \n",
        "\n",
        "Fortunately, it only the procedure only takes a couple of minutes and it is fully automated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eIWfDqQ3Cqi",
        "cellView": "form"
      },
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install PySpark\n",
        "!pip install pyspark findspark --quiet\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L2O_3I3x1dbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#Example\n",
        "### Weblog Sender\n",
        "The stream server is a small python TCP server, listening\n",
        "on port 7777 (localhost). \n",
        "\n",
        "The stream will consist of a set of text lines, obtained from the output log of a webserver.\n",
        "\n"
      ],
      "metadata": {
        "id": "51ECJ--i0D2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - https://github.com/smduarte/ps2022/raw/main/colab/logsender.tgz | tar xfz - 2> /dev/null\n",
        "\n",
        "!nohup python logsender/server.py logsender/web.log 7777 > /dev/null 2> /dev/null &"
      ],
      "metadata": {
        "id": "GElosFxt-D4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The python code below shows the basics needed to process data from socket source using PySpark.\n",
        "\n",
        "Spark Streaming python documentation is found [here](https://spark.apache.org/docs/latest/api/python/reference/pyspark.streaming.html)"
      ],
      "metadata": {
        "id": "1wihC26vaiT1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpO0aX2PPWd1"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext(\"local[2]\", \"WebLogExample\")\n",
        "import socket\n",
        "from pyspark.streaming import StreamingContext\n",
        "\n",
        "ssc = StreamingContext(sc, 1)\n",
        "lines = ssc.socketTextStream(\"localhost\", 7777)\n",
        "\n",
        "lines.pprint()\n",
        "\n",
        "ssc.start()\n",
        "ssc.awaitTermination(10)\n",
        "ssc.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Exercises\n",
        "\n",
        "Do the follwing exercises:\n",
        "\n",
        "**Every 3 seconds**, \n",
        "1. Dump the number of requests in the last 10 seconds;\n",
        "2. Dump the number of requests in the last 10 seconds, only if they total more than 100;\n",
        "3. Dump the number of requests in the last 10 seconds, if there is an IP address with more than 100 requests;\n",
        "4. Dump the proportion of IPv4 vs IPv6 requests in the last 20 seconds.\n",
        "\n"
      ],
      "metadata": {
        "id": "THPCe5kkaEr-"
      }
    }
  ]
}